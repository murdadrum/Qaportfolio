<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Web Crawler &amp; Data Scraper</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <style>:root{color-scheme:dark;--bg-900:#0b1220;--bg-800:#0f1b2d;--bg-700:#14243b;--text-100:#e2e8f0;--text-300:#cbd5f5;--text-500:#94a3b8;--accent-500:#38bdf8;--accent-400:#7dd3fc;--accent-300:#a5b4fc;--success-400:#4ade80}*{box-sizing:border-box}body{margin:0;font-family:"Space Grotesk","IBM Plex Sans",system-ui,sans-serif;background:radial-gradient(circle at top,#1d2b4a 0%,#0b1220 48%,#020617 100%);color:var(--text-100);min-height:100vh}a{color:var(--accent-400);text-decoration:none}a:hover{color:var(--accent-500)}.page{max-width:1120px;margin:0 auto;padding:48px 20px 72px}.top-bar{display:flex;justify-content:space-between;align-items:center;margin-bottom:24px}.badge{display:inline-flex;align-items:center;gap:8px;padding:6px 14px;border-radius:999px;background:rgba(59,130,246,.18);color:#c7d2fe;font-size:12px;text-transform:uppercase;letter-spacing:.18em}.cta{display:inline-flex;align-items:center;gap:8px;padding:8px 16px;border-radius:999px;background:rgba(56,189,248,.16);color:#bae6fd;font-size:13px}header{display:grid;gap:20px;margin-bottom:36px}.title{font-size:clamp(32px,4vw,44px);line-height:1.05;margin:0}.subtitle{font-size:18px;color:var(--text-500);max-width:760px;margin:0}.meta{display:flex;flex-wrap:wrap;gap:12px;align-items:center}.pill{display:inline-flex;align-items:center;padding:6px 12px;border-radius:999px;background:rgba(148,163,184,.16);font-size:12px;color:var(--text-100)}.section{margin-top:32px}.section h2{font-size:16px;text-transform:uppercase;letter-spacing:.2em;color:var(--accent-300);margin:0 0 14px}.grid{display:grid;gap:16px;grid-template-columns:repeat(auto-fit,minmax(240px,1fr))}.card{padding:18px;border-radius:16px;background:rgba(15,23,42,.7);border:1px solid rgba(148,163,184,.12);box-shadow:0 18px 40px rgba(2,6,23,.45)}.card h3{margin:0 0 8px;font-size:16px}.card p{margin:0;color:var(--text-500);font-size:14px;line-height:1.5}.list{display:grid;gap:10px;margin:0;padding:0}.list-item{display:flex;gap:10px;align-items:flex-start;font-size:14px;color:var(--text-300)}.dot{width:8px;height:8px;border-radius:50%;background:linear-gradient(135deg,var(--accent-500),var(--accent-300));margin-top:6px;flex-shrink:0}.kpi{display:grid;gap:6px;border-radius:14px;padding:14px;background:rgba(20,36,59,.6)}.kpi span{color:var(--text-500);font-size:12px;text-transform:uppercase;letter-spacing:.14em}.kpi strong{font-size:16px;color:var(--text-100)}.pipeline{display:grid;gap:12px}.pipeline-step{display:grid;gap:6px;padding:14px 16px;border-radius:14px;background:rgba(34,197,94,.12);color:#dcfce7}.pipeline-step span{font-size:12px;letter-spacing:.12em;text-transform:uppercase;color:#bbf7d0}.code-block{background:#0b1325;border:1px solid rgba(148,163,184,.2);border-radius:16px;padding:16px;font-family:"SF Mono","JetBrains Mono",monospace;font-size:12px;color:#e2e8f0;white-space:pre-wrap}.flow{display:flex;flex-wrap:wrap;gap:10px}.flow span{padding:6px 12px;border-radius:12px;background:rgba(34,197,94,.14);color:#bbf7d0;font-size:12px}footer{margin-top:40px;color:var(--text-500);font-size:12px}@media (max-width:700px){.top-bar{flex-direction:column;align-items:flex-start;gap:12px}}</style>
  </head>
  <body>
    <div class="page">
      <div class="top-bar">
        <span class="badge">QA Case Study</span>
        <a class="cta" href="/">‚Üê Back to Portfolio</a>
      </div>

      <header>
        <h1 class="title">Web Crawler &amp; Data Scraper</h1>
        <p class="subtitle">Robust crawling and scraping platform with dynamic rendering and data quality validation.</p>
        <div class="meta">
          <span class="pill">Python</span><span class="pill">Scrapy</span><span class="pill">Selenium</span><span class="pill">BeautifulSoup</span><span class="pill">MongoDB</span>
          <a class="pill" href="https://github.com/murdadrum/web-crawler-data-scraper" target="_blank" rel="noreferrer">GitHub Repo</a>
        </div>
      </header>

      <section class="section">
        <h2>Executive Summary</h2>
        <div class="grid">
          <div class="card">
            <h3>Challenge</h3>
            <p>High-volume data collection suffered from bot defenses and inconsistent parsing results.</p>
          </div>
          <div class="card">
            <h3>Solution</h3>
            <p>Combined Scrapy spiders with Selenium fallbacks and QA validation on extracted data.</p>
          </div>
          <div class="card">
            <h3>Impact</h3>
            <p>Stabilized scraping throughput while improving data accuracy and monitoring coverage.</p>
          </div>
        </div>
      </section>

      <section class="section">
        <h2>Coverage Map</h2>
        <div class="grid">
        <div class="card">
          <h3>Dynamic Content</h3>
          <p>JavaScript-rendered pages and lazy-loaded data.</p>
        </div>
        <div class="card">
          <h3>Pagination</h3>
          <p>Multi-page navigation and deep indexing.</p>
        </div>
        <div class="card">
          <h3>Anti-bot</h3>
          <p>Rate limits, retries, and proxy rotation.</p>
        </div>
        <div class="card">
          <h3>Data QA</h3>
          <p>Schema checks and anomaly detection.</p>
        </div></div>
      </section>

      <section class="section">
        <h2>Automation Layers</h2>
        <div class="grid">
        <div class="card">
          <h3>Scrapy Spiders</h3>
          <p>High-throughput crawling with structured parsing.</p>
        </div>
        <div class="card">
          <h3>Selenium Fallbacks</h3>
          <p>Dynamic rendering for complex pages.</p>
        </div>
        <div class="card">
          <h3>Quality Checks</h3>
          <p>Completeness, duplicates, and schema enforcement.</p>
        </div>
        <div class="card">
          <h3>Monitoring</h3>
          <p>Uptime and crawl performance dashboards.</p>
        </div></div>
      </section>

      <section class="section">
        <h2>Quality Signals Tracked</h2>
        <div class="grid">
        <div class="kpi">
          <span>Throughput</span>
          <strong>Pages scraped per hour.</strong>
        </div>
        <div class="kpi">
          <span>Quality</span>
          <strong>Parse error and validation failure rates.</strong>
        </div>
        <div class="kpi">
          <span>Coverage</span>
          <strong>URL coverage across target domains.</strong>
        </div>
        <div class="kpi">
          <span>Stability</span>
          <strong>Retry success and error recovery.</strong>
        </div></div>
      </section>

      <section class="section">
        <h2>CI/CD Pipeline Gates</h2>
        <div class="pipeline">
        <div class="pipeline-step">
          <span>Stage 1</span>
          Seed crawl queue and start spider.
        </div>
        <div class="pipeline-step">
          <span>Stage 2</span>
          Parse + validate data payloads.
        </div>
        <div class="pipeline-step">
          <span>Stage 3</span>
          Persist to storage + publish logs.
        </div>
        <div class="pipeline-step">
          <span>Stage 4</span>
          Run monitoring + anomaly alerts.
        </div></div>
      </section>

      <section class="section">
        <h2>Artifacts & Reporting</h2>
        <div class="flow"><span>Crawler Logs</span><span>Data QA Report</span><span>Scheduler Config</span><span>Error Summary</span></div>
      </section>

      <section class="section">
        <h2>Sample Scrapy Spider</h2>
        <div class="code-block">class ProductSpider(scrapy.Spider):
    name = "products"
    start_urls = ["https://example.com/catalog"]

    def parse(self, response):
        for item in response.css('.product'):
            yield {
                'name': item.css('h2::text').get(),
                'price': item.css('.price::text').get(),
            }</div>
      </section>

      <section class="section">
        <h2>Validation Flow</h2>
        <div class="flow"><span>Fetch</span><span>Parse</span><span>Validate</span><span>Store</span></div>
      </section>

      <footer>
        Portfolio case study scaffold. Replace placeholders with live outputs when ready.
      </footer>
    </div>
  </body>
</html>